{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f4c79c0-1e76-4968-ae5f-a3a6ee3161cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-19 17:22:16.204000: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb030a31-72a1-4370-8727-82fb3256b9c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2645850218.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    if USE_EXSISTING_MODEL\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "IMG_HEIGHT = 316\n",
    "IMG_WIDTH = 384\n",
    "BATCH_SIZE = 16\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "USE_EXSISTING_MODEL = False\n",
    "\n",
    "Sections = [ \"Gravel\", \"ramp\" ]\n",
    "\n",
    "Section_histories = []\n",
    "\n",
    "for Section in Sections:\n",
    "    DATA_DIR = '/home/fizzer/ros_ws/training_for_driving/' + Section + '/images' \n",
    "    if USE_EXSISTING_MODEL:\n",
    "        model = tf.keras.models.load_model('/home/fizzer/ros_ws/training_for_driving/'+Section+'/best_model.h5')\n",
    "    else:\n",
    "        model = create_model()\n",
    "    history = Train(model, DATA_DIR, Section)\n",
    "    Section_histories.append(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858502b6-6ec4-48cf-adc8-dd94caf8f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(filename):\n",
    "    # Extract filename from path\n",
    "    filename_only = tf.strings.split(filename, os.path.sep)[-1]\n",
    "    \n",
    "    # Regex pattern to capture Lin and Ang values\n",
    "    pattern = r'.*_Lin_(-?\\d+\\.\\d{2})_Ang_(-?\\d+\\.\\d{2})\\.png$'\n",
    "    \n",
    "    # Extract values using regex replace and split\n",
    "    lin_ang_str = tf.strings.regex_replace(filename_only, pattern, r'\\1,\\2')\n",
    "    parts = tf.strings.split(lin_ang_str, ',')\n",
    "    \n",
    "    # Convert to floats\n",
    "    lin = tf.strings.to_number(parts[0], tf.float32)\n",
    "    ang = tf.strings.to_number(parts[1], tf.float32)\n",
    "    \n",
    "    return tf.stack([lin, ang])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29da9dc0-9bab-4624-ac41-f411040ee2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir):\n",
    "    # List all PNG files\n",
    "    ds = tf.data.Dataset.list_files(os.path.join(data_dir, \"*.png\"), shuffle=True)\n",
    "    \n",
    "    # Get cardinality as tensor\n",
    "    cardinality = tf.data.experimental.cardinality(ds)\n",
    "    \n",
    "    # Calculate split sizes using TensorFlow operations\n",
    "    val_size = tf.cast(\n",
    "        tf.cast(cardinality, tf.float32) * VAL_SPLIT,\n",
    "        tf.int64\n",
    "    )\n",
    "    train_size = cardinality - val_size\n",
    "\n",
    "    # Split dataset\n",
    "    train_ds = ds.skip(val_size)\n",
    "    val_ds = ds.take(val_size)\n",
    "\n",
    "    # Rest of the processing remains the same...\n",
    "    def process_path(file_path):\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.io.decode_png(img, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        return img, parse_labels(file_path)\n",
    "\n",
    "    train_ds = train_ds.shuffle(10000).map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c73cc203-01b8-41e2-89c0-4fbb58f7c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        \n",
    "        # Enhanced convolutional base\n",
    "        layers.Conv2D(64, (5, 5), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Dense layers with L2 regularization\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Dense(2, activation='tanh')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # Lower initial LR\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3da64b-d68b-44b7-84c6-b0ec71149a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, DATA_DIR, Section):\n",
    "\n",
    "    train_dataset, val_dataset = create_dataset(DATA_DIR)\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,  # Increased from 10\n",
    "            min_delta=0.00001,  # Minimum change to qualify as improvement\n",
    "            mode='min',\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,  # Wait longer before reducing LR\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            '/home/fizzer/ros_ws/training_for_driving/'+Section+'/best_model.h5',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=100,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b992ef-5c57-4baa-9110-a29a2a26cd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
