{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4c79c0-1e76-4968-ae5f-a3a6ee3161cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 00:12:41.463953: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb030a31-72a1-4370-8727-82fb3256b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 00:17:24.251406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.270059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.270207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.271108: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-02 00:17:24.271839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.271931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.271988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.552942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.553039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.553098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-02 00:17:24.553172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6116 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 00:17:25.602828: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2025-04-02 00:17:26.812637: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1094 [==============================] - 109s 97ms/step - loss: 0.1169 - mae: 0.2139 - val_loss: 0.1749 - val_mae: 0.2733 - lr: 7.8125e-06\n",
      "Epoch 2/100\n",
      "  42/1094 [>.............................] - ETA: 1:34 - loss: 0.1166 - mae: 0.2158"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "IMG_HEIGHT = 316\n",
    "IMG_WIDTH = 384\n",
    "BATCH_SIZE = 16\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "USE_EXISTING_MODEL = True\n",
    "\n",
    "Sections = [\"Gravel\"]\n",
    "\n",
    "Section_histories = []\n",
    "\n",
    "for Section in Sections:\n",
    "    DATA_DIR = '/home/fizzer/ros_ws/training_for_driving/' + Section + '/images' \n",
    "    if USE_EXISTING_MODEL:\n",
    "        model = tf.keras.models.load_model('/home/fizzer/ros_ws/training_for_driving/'+Section+'/best_model.h5')\n",
    "    else:\n",
    "        model = create_model()\n",
    "    history = Train(model, DATA_DIR, Section)\n",
    "    Section_histories.append(history)\n",
    "    \n",
    "plot_histories(Section_histories, Sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858502b6-6ec4-48cf-adc8-dd94caf8f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(filename):\n",
    "    # Extract filename from path\n",
    "    filename_only = tf.strings.split(filename, os.path.sep)[-1]\n",
    "    \n",
    "    # Regex pattern to capture Lin and Ang values\n",
    "    pattern = r'.*_Lin_(-?\\d+\\.\\d{2})_Ang_(-?\\d+\\.\\d{2})\\.png$'\n",
    "    \n",
    "    # Extract values using regex replace and split\n",
    "    lin_ang_str = tf.strings.regex_replace(filename_only, pattern, r'\\1,\\2')\n",
    "    parts = tf.strings.split(lin_ang_str, ',')\n",
    "    \n",
    "    # Convert to floats\n",
    "    lin = tf.strings.to_number(parts[0], tf.float32)\n",
    "    ang = tf.strings.to_number(parts[1], tf.float32)\n",
    "    \n",
    "    return tf.stack([lin, ang])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29da9dc0-9bab-4624-ac41-f411040ee2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir):\n",
    "    # List all PNG files\n",
    "    ds = tf.data.Dataset.list_files(os.path.join(data_dir, \"*.png\"), shuffle=True)\n",
    "    \n",
    "    # Get cardinality as tensor\n",
    "    cardinality = tf.data.experimental.cardinality(ds)\n",
    "    \n",
    "    # Calculate split sizes using TensorFlow operations\n",
    "    val_size = tf.cast(\n",
    "        tf.cast(cardinality, tf.float32) * VAL_SPLIT,\n",
    "        tf.int64\n",
    "    )\n",
    "    train_size = cardinality - val_size\n",
    "\n",
    "    # Split dataset\n",
    "    train_ds = ds.skip(val_size)\n",
    "    val_ds = ds.take(val_size)\n",
    "\n",
    "    # Rest of the processing remains the same...\n",
    "    def process_path(file_path):\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.io.decode_png(img, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        return img, parse_labels(file_path)\n",
    "\n",
    "    train_ds = train_ds.shuffle(10000).map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c73cc203-01b8-41e2-89c0-4fbb58f7c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        \n",
    "        # Enhanced convolutional base\n",
    "        layers.Conv2D(64, (5, 5), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Dense layers with L2 regularization\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Dense(2, activation='tanh')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # Lower initial LR\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3da64b-d68b-44b7-84c6-b0ec71149a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(model, DATA_DIR, Section):\n",
    "\n",
    "    train_dataset, val_dataset = create_dataset(DATA_DIR)\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,  # Increased from 10\n",
    "            min_delta=0.00001,  # Minimum change to qualify as improvement\n",
    "            mode='min',\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,  # Wait longer before reducing LR\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            '/home/fizzer/ros_ws/training_for_driving/'+Section+'/best_model.h5',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=100,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b992ef-5c57-4baa-9110-a29a2a26cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histories(histories, sections):\n",
    "    \"\"\"Dynamically plots loss and accuracy for multiple training histories.\"\"\"\n",
    "    \n",
    "    # Determine available metrics dynamically\n",
    "    all_metrics = set()\n",
    "    for history in histories:\n",
    "        if history is not None:\n",
    "            all_metrics.update(history.history.keys())\n",
    "\n",
    "    loss_metrics = [m for m in all_metrics if 'loss' in m]\n",
    "    acc_metrics = [m for m in all_metrics if 'accuracy' in m or 'acc' in m]\n",
    "\n",
    "    num_plots = len(loss_metrics) + len(acc_metrics)\n",
    "    \n",
    "    # Ensure at least one plot is created\n",
    "    if num_plots == 0:\n",
    "        print(\"No metrics found in histories.\")\n",
    "        return\n",
    "    \n",
    "    fig, axs = plt.subplots(num_plots, 1, figsize=(10, 5 * num_plots))\n",
    "    \n",
    "    # Convert axs to a list if only one subplot is created\n",
    "    if num_plots == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    plot_idx = 0\n",
    "    \n",
    "    # Plot all loss-related metrics\n",
    "    for loss_metric in loss_metrics:\n",
    "        for i, history in enumerate(histories):\n",
    "            if history is None:\n",
    "                continue\n",
    "            label = sections[i]\n",
    "            axs[plot_idx].plot(history.history[loss_metric], label=f\"{label} - {loss_metric}\")\n",
    "        axs[plot_idx].set_title(loss_metric.replace('_', ' ').title())\n",
    "        axs[plot_idx].set_ylabel(\"Loss\")\n",
    "        axs[plot_idx].set_xlabel(\"Epoch\")\n",
    "        axs[plot_idx].legend()\n",
    "        plot_idx += 1\n",
    "\n",
    "    # Plot all accuracy-related metrics\n",
    "    for acc_metric in acc_metrics:\n",
    "        for i, history in enumerate(histories):\n",
    "            if history is None:\n",
    "                continue\n",
    "            label = sections[i]\n",
    "            axs[plot_idx].plot(history.history[acc_metric], label=f\"{label} - {acc_metric}\")\n",
    "        axs[plot_idx].set_title(acc_metric.replace('_', ' ').title())\n",
    "        axs[plot_idx].set_ylabel(\"Accuracy\")\n",
    "        axs[plot_idx].set_xlabel(\"Epoch\")\n",
    "        axs[plot_idx].legend()\n",
    "        plot_idx += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34225ccd-b450-47b1-8618-9e71e0f34c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa4a7c-6203-479e-9751-b1669eebcaf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
