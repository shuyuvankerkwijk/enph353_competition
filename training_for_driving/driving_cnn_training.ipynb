{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f4c79c0-1e76-4968-ae5f-a3a6ee3161cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb030a31-72a1-4370-8727-82fb3256b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "267/267 [==============================] - 57s 212ms/step - loss: 1.7897 - mae: 0.3536 - val_loss: 0.3883 - val_mae: 0.4033 - lr: 5.0000e-04\n",
      "Epoch 2/100\n",
      "176/267 [==================>...........] - ETA: 16s - loss: 0.2038 - mae: 0.2930"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "IMG_HEIGHT = 316\n",
    "IMG_WIDTH = 384\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "SEED = 42\n",
    "\n",
    "Sections = [ \"Gravel\", \"OffRoad\", \"ramp\" ]\n",
    "\n",
    "Section_histories = []\n",
    "\n",
    "for Section in Sections:\n",
    "    DATA_DIR = \"/home/fizzer/images_for_cnn_training/\" + Section + '/images' \n",
    "    Section_histories.append(create_and_train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "858502b6-6ec4-48cf-adc8-dd94caf8f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_labels(filename):\n",
    "    # Extract filename from path\n",
    "    filename_only = tf.strings.split(filename, os.path.sep)[-1]\n",
    "    \n",
    "    # Regex pattern to capture Lin and Ang values\n",
    "    pattern = r'.*_Lin_(-?\\d+\\.\\d{2})_Ang_(-?\\d+\\.\\d{2})\\.png$'\n",
    "    \n",
    "    # Extract values using regex replace and split\n",
    "    lin_ang_str = tf.strings.regex_replace(filename_only, pattern, r'\\1,\\2')\n",
    "    parts = tf.strings.split(lin_ang_str, ',')\n",
    "    \n",
    "    # Convert to floats\n",
    "    lin = tf.strings.to_number(parts[0], tf.float32)\n",
    "    ang = tf.strings.to_number(parts[1], tf.float32)\n",
    "    \n",
    "    return tf.stack([lin, ang])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29da9dc0-9bab-4624-ac41-f411040ee2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_dir):\n",
    "    # List all PNG files\n",
    "    ds = tf.data.Dataset.list_files(os.path.join(data_dir, \"*.png\"), shuffle=True)\n",
    "    \n",
    "    # Get cardinality as tensor\n",
    "    cardinality = tf.data.experimental.cardinality(ds)\n",
    "    \n",
    "    # Calculate split sizes using TensorFlow operations\n",
    "    val_size = tf.cast(\n",
    "        tf.cast(cardinality, tf.float32) * VAL_SPLIT,\n",
    "        tf.int64\n",
    "    )\n",
    "    train_size = cardinality - val_size\n",
    "\n",
    "    # Split dataset\n",
    "    train_ds = ds.skip(val_size)\n",
    "    val_ds = ds.take(val_size)\n",
    "\n",
    "    # Rest of the processing remains the same...\n",
    "    def process_path(file_path):\n",
    "        img = tf.io.read_file(file_path)\n",
    "        img = tf.io.decode_png(img, channels=3)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        return img, parse_labels(file_path)\n",
    "\n",
    "    train_ds = train_ds.shuffle(10000).map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    val_ds = val_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c73cc203-01b8-41e2-89c0-4fbb58f7c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Rescaling(1./255, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        \n",
    "        # Enhanced convolutional base\n",
    "        layers.Conv2D(64, (5, 5), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Dense layers with L2 regularization\n",
    "        layers.Dense(512, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer='l2'),\n",
    "        layers.Dense(2, activation='tanh')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # Lower initial LR\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f3da64b-d68b-44b7-84c6-b0ec71149a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train():\n",
    "\n",
    "    train_dataset, val_dataset = create_dataset(DATA_DIR)\n",
    "    model = create_model()\n",
    "    \n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,  # Increased from 10\n",
    "            min_delta=0.00001,  # Minimum change to qualify as improvement\n",
    "            mode='min',\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,  # Wait longer before reducing LR\n",
    "            verbose=1\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            '/home/fizzer/images_for_cnn_training/'+Section+'/best_model.h5',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            monitor='val_loss'\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=val_dataset,\n",
    "        epochs=100,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8397235-a64c-4068-ac7d-08279740aea9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# To save: plt.savefig('training_history.png', dpi=300)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Visualize after training\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m plot_training_history(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    # Create subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 15))\n",
    "    \n",
    "    # Plot Loss\n",
    "    ax1.plot(history.history['loss'], label='Train Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('MSE')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot MAE\n",
    "    ax2.plot(history.history['mae'], label='Train MAE')\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE')\n",
    "    ax2.set_title('Mean Absolute Error')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # To save: plt.savefig('training_history.png', dpi=300)\n",
    "\n",
    "# Visualize after training\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b992ef-5c57-4baa-9110-a29a2a26cd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
